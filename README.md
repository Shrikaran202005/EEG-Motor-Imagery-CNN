EEG-Motor-Imagery-Classification
ðŸ“Œ Overview

This project implements a spectrogram-based deep learning pipeline for EEG Motor Imagery (MI) classification, leveraging the BCI Competition IV Datasets (2a & 2b). Using advanced preprocessing techniques and a custom CNN architecture enhanced with Squeeze-and-Excitation (SE) blocks, the system achieves high classification accuracy across subjects.

The pipeline transforms raw EEG signals into Short-Time Fourier Transform (STFT) spectrograms and trains robust deep learning models to recognize motor imagery tasks such as left hand, right hand, foot, and tongue movements.

âœ¨ Features

Preprocessing pipeline:

Common Average Referencing (CAR)

Notch Filter (50 Hz)

Bandpass Filter (8â€“30 Hz, Mu & Beta rhythms)

Minâ€“Max Normalization

Sliding Window Segmentation

STFT-based Spectrogram Generation

Deep Learning Architecture:

Convolutional Neural Network (CNN)

Squeeze-and-Excitation (SE) blocks for channel attention

Spectrogram Augmentation (time & frequency masking)

Lazy Dataset Loading for large EEG files

Datasets:

BCI Competition IV â€“ Dataset 2a (4-class: left, right, foot, tongue)

BCI Competition IV â€“ Dataset 2b (2-class: left, right)

Results:

Dataset 2a â†’ ~90â€“96% accuracy

Dataset 2b â†’ ~97â€“99% accuracy

ðŸ“‚ Repository Structure
â”œâ”€â”€ data/                # EEG datasets (.gdf or preprocessed .npy)
â”œâ”€â”€ preprocessing/       # Preprocessing scripts (CAR, filters, STFT, segmentation)
â”œâ”€â”€ models/              # CNN architectures with SE blocks
â”œâ”€â”€ training/            # Training pipeline & evaluation scripts
â”œâ”€â”€ utils/               # Helper functions (augmentation, dataset loader)
â”œâ”€â”€ results/             # Saved models, logs, and evaluation metrics
â””â”€â”€ README.md

ðŸš€ Getting Started
1. Clone Repository
git clone https://github.com/your-username/EEG-Motor-Imagery-Classification.git
cd EEG-Motor-Imagery-Classification

2. Install Dependencies
pip install -r requirements.txt

3. Dataset Setup

Download BCI Competition IV 2a/2b datasets (.gdf files).

Place them inside data/ directory.

4. Run Preprocessing
python preprocessing/preprocess_gdf.py --dataset 2a

5. Train Model
python training/train_cnn.py --dataset 2a --augment True

6. Evaluate Model
python training/evaluate.py --dataset 2a

ðŸ“Š Results & Analysis

2a (4-class MI): Achieved ~90â€“96% accuracy, with some misclassifications between left/right and foot/tongue imagery.

2b (2-class MI): Achieved ~97â€“99% accuracy, with minimal confusion.

Average confusion matrices demonstrate strong diagonal dominance across subjects.

ðŸ§  Applications

Brain-Computer Interfaces (BCIs)

Neuro-rehabilitation

Assistive technologies for motor-impaired individuals

Real-time control systems

ðŸ“œ License

This project is released under the MIT License.

ðŸ‘¤ Author

Developed as part of an academic project at NIT.
